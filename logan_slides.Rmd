---
title: "Untitled"
author: "Logan Harris"
date: "`r Sys.Date()`"
output: 
  ioslides_presentation:
    widescreen: true
    css: slides.css
    logo: images/logo.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Notes

- The specification of the joint model is very flexible 
- Focus on a specification that can be directly linked to the extensions in the paper
- Generalizations will be noted as they could be interesting to keep in mind
- More along the lines as presented in 2004 paper
- Mix of 2000, 2004, out, and paper's notation

## General assumptions

- Subjects assumed independent

## Joint Modeling

- The general concept is rather simple:
  1. We have longitudinal data
  2. We have survival data
  3. We want to model them in a way that the models borrow information from one another
- Longitudinal data can inform survival outcome
  - e.g. CD4 cell count and the time to progression to AIDS or death
- Survival can inform longitudinal data by accounting for dropout related to outcome
  - e.g. Missed visits due to death likely provides information on the unobserved trajectory of CD4 cell count
  
## Survival Data Background

- *Censoring* occurs when we do not observe a subject until they experience the event of interest
  - May occur due to study ending, death due to another cause, or unrelated circumstances
- Let $T_i^*$ be the actual survival time, which may or may not be observed due to censoring
  - The reason for $^*$ is to distingish this time from the measurement times in the longitudinal data
- Let $C_i$ be the censoring time
- Define $R_i$ = $min(T_i^*, C_i)$, we call this the *observed time*
- Finally, define $\Delta_i = I(T_i^* \leq C_i)$ to be the indicator of if the even was observed or not

## Modeling Survival Data 

- As the name may imply, survival data depends on the survival distribution (S(t))
- However, usually, the surivial function is defined in terms of a hazard function
- The hazard function represents the instantaneous failure rate at time $t$.
- More specifically, it is the probability that a subject will fail in at time $t$ given that $T > t$
- $h(t) = \lim_{\delta \rightarrow 0} \frac{P(t < T < t + \delta | T > t)}{\delta}$
- $h(t)$ relates to $S(t)$ by $h(t) = \frac{f(t)}{S(t)}$ where $f(t) = -\frac{d}{dt}S(t) =\frac{d}{dt}F(t)$.
- The hazard is often modeled using the Cox PH model:

$$
h(t|x) = h_0(t)exp \Big[Z_i \gamma \Big]
$$

- The above included only constant covariates

## Time Dependent Covariates

- Consider the following extension:

$$
h(t|x) = h_0(t)exp \Big[\boldsymbol{X}(t)\boldsymbol{\beta} + Z_i \gamma \Big]
$$

- This indicates that $\boldsymbol{X}$ may be time dependent
- "May" is critical for this presentation, $\boldsymbol{X}(t)$ is currently an abuse of notation
- Purely used to align with how the notation is presented in the paper.

## Back to Longitudinal

- Model X_(u) with random intercept and slope
- measured at times $t_{ij}$

$$
Y_{ij} = \mu_i + X_{i0} + X_{i1}T_{ij} + W_{ij} \\
$$

- $Y_{ij}$ is the value actually observed at time $t_ij$
- $X_{i0}$ is a random intercept, and $X_{i1}$ a random slope
- $W_{ij}$ is random Normal error
- There is a wide array of ways to specify these components in essentially any way you could think to generalize them
- As a general example, you could have:

$$
\begin{aligned}
\mu_i &= \mu \\
\mu_i &= \boldsymbol{X}_i\boldsymbol{\beta} \\
\mu_i &= \boldsymbol{X}_i(t)\boldsymbol{\beta} \\
\mu_i &= \mu_i(t)
\end{aligned}
$$

- Similar extensions can be made with the random effects and $T_ij$ in that the form can be made flexible


## Extension to Imagining Data

- First, let $\mu_i &= \mu$

$$
Y_{ij} = \mu + X_{i0} + X_{i1}T_{ij} + W_{ij} \\
$$

- Then note that we can model each voxel at a given visit $j$:

$$
Y_{ij}(v) = \mu(v) + X_{i0}(v) + X_{i1}(v)T_{ij} + W_{ij}(v) \\
$$
- This extension is of course not trivial, as this is now a functional mixed effects model

## Analogies

- As a starting place, consider a survival model with a time dependent covariate. 
- On the flip side, we could also consider the information provided to longitudinally collected data 
- If the processes are modeled independently can lead to biased estimates for the longitudinal model

## Combining Models: The Survival model

- Recall the form presented previously:

$$
h(t|x) = h_0(t)exp \Big[\boldsymbol{X}_i(t)\boldsymbol{\beta} + Z_i \gamma \Big]
$$

- We will leave the fixed covariates as is, however, we will include the **REs** from the longitudinal model above as time varying covariates
- With that said, survival is a univariate outcome, and we have brain scan data that is of much higher dimension
  - Integrate over this information

$$
h(t|X_{i0}(v), X_{i1}(v), \boldsymbol{Z}_i) = h_0(t) exp \Big[ \int_{V} \lbrace X_{i0}(v)\beta_0(v) + tX_{i1}(v)\beta_1(v)\rbrace dv + Z_i \gamma \Big]
$$

## Note

- There can be additional relationships made by introducing REs int the survival model that are correlated with those in the longitudinal model
- In the absence of association between longitudinal and event time data, the joint analysis shoudl recover the same results as if the analyses were done speratly.

## Estimation

- The route of estimation largely depends on the data at hand and the end goal
- One simple way to go about this is to use a two stage approach:
  1. Estimate the longitudinal model
  2. Use estimates from (1) in the survival model
- However this has been shown to lead to considerable bias when measurement error in the longitudinal observations are large
- Different asusmptions and resulting models need different tools for estimation
- Many approaches use an EM algorithm adapted to the specific problem at hand
- Other approaches have taken a Bayesian approach and developed MCMC algorithms
- Given the complexity of the problem being solved here, the authors adopted a Bayesian approach to be described later


## Bayesian Details: Priors

Unknown Parameters:

$$
\begin{aligned}
\boldsymbol{\beta}_0 \sim N(\boldsymbol{0}, \sigma^2_{\beta_0}I_{N_0}) \\
\boldsymbol{\beta}_1 \sim N(\boldsymbol{0}, \sigma^2_{\beta_1}I_{N_1}) \\
\boldsymbol{\gamma} \sim N(\boldsymbol{0}, \sigma^2_{\gamma}I_{q})
\end{aligned}
$$

- The $\sigma^2$s are taken to be large when prior knowledge is not available

Variance Components:

For $k = 1, \ldots, N_0$, $l = 1, \ldots, N_1$, $m = 1, \ldots, N_w$,

$$
\begin{aligned}
\lambda_k^{X0} \sim IG(a_k^{X0}, b_k^{X0}) \\
\lambda_l^{X1} \sim IG(a_l^{X1}, b_l^{X1}) \\
\lambda_m^{W} \sim IG(a_m^{W}, b_m^{W}) \\
\end{aligned}
$$

- Empirical Bayes can be used to help choose hyper parameters
- For example: $a_k^{X0} \leq 0.01$, $b_k^{X0} \leq 0.01\tilde{\lambda}_k^{X0}$, where $\tilde{\lambda}_k^{X0}$ is the EB estimator


Hazard values:

For $g = 1, \ldots, G$,

$$
h_g \sim Gamma(\alpha_{1g}, \alpha_{2g})
$$

- With $(\alpha_{1g}, \alpha_{2g})$ often set to $(0.2, 0.4)$ or $(0.5, 1)$ to result in a flat prior.

## Bayesian Details: Sampling

- Metropolis-hastings within Gibbs to sample from $p(\boldsymbol{\theta}, \boldsymbol{\xi},   \boldsymbol{\zeta}  | \boldsymbol{D})$

- $\boldsymbol{\eta}_{ij}$ can automatically be updated: $\boldsymbol{\eta}_{ij} = (\Psi^{W'}\Psi^{W})^{-1}\Psi^{W'}(\tilde{\boldsymbol{Y}}_{ij} - \Psi^{X0}\boldsymbol{\xi}_i - T_{ij}\Psi^{X1}\boldsymbol{\zeta})$
- Add in the full conditionals

- The last 4, are of course easy to sample from
- The other two are where the MH step comes in: 
  - Use a multivariate normal 
    1. mean at the current value of the parameters of interest
    2. Covariance proportional to the inverse of the fisher information of the posterior
      - Use a small variance parameter to turn acceptance rate to be approximately 35%
      
## Bayesian Details: Prediction

- Focus on the time interval $(t, t + \delta]$
- Conditional on survivng up to time $t$, the conditional probability of survival up to time $t +\delta$

## Simulation Summary

## Extensions

- Covariates can be shared across models


